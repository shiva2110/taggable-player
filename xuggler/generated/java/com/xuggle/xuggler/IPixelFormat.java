/* ----------------------------------------------------------------------------
 * This file was automatically generated by SWIG (http://www.swig.org).
 * Version 2.0.0
 *
 * Do not make changes to this file unless you know what you are doing--modify
 * the SWIG interface file instead.
 * ----------------------------------------------------------------------------- */

package com.xuggle.xuggler;
import com.xuggle.ferry.*;
/**
 * Information about how video data is formatted in an {@link IVideoPicture} 
 * object.  
 * This specifies the color space and how many bits pixel data takes. 
 * It also  
 * includes some utility methods for dealing with {@link Type#YUV420P} 
 * data; the  
 * most common type of encoding used in video files I've run across. 
 *  
 */
public class IPixelFormat extends RefCounted {
  // JNIHelper.swg: Start generated code
  // >>>>>>>>>>>>>>>>>>>>>>>>>>>
  /**
   * This method is only here to use some references and remove
   * a Eclipse compiler warning.
   */
  @SuppressWarnings("unused")
  private void noop()
  {
    IBuffer.make(null, 1);
  }
   
  private volatile long swigCPtr;

  /**
   * Internal Only.
   */
  protected IPixelFormat(long cPtr, boolean cMemoryOwn) {
    super(XugglerJNI.SWIGIPixelFormatUpcast(cPtr), cMemoryOwn);
    swigCPtr = cPtr;
  }
  
  /**
   * Internal Only.
   */
  protected IPixelFormat(long cPtr, boolean cMemoryOwn,
      java.util.concurrent.atomic.AtomicLong ref)
  {
    super(XugglerJNI.SWIGIPixelFormatUpcast(cPtr),
     cMemoryOwn, ref);
    swigCPtr = cPtr;
  }
    
  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that obj is proxying for.
   *   
   * @param obj The java proxy object for a native object.
   * @return The raw pointer obj is proxying for.
   */
  public static long getCPtr(IPixelFormat obj) {
    if (obj == null) return 0;
    return obj.getMyCPtr();
  }

  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that we're proxying for.
   *   
   * @return The raw pointer we're proxying for.
   */  
  public long getMyCPtr() {
    if (swigCPtr == 0) throw new IllegalStateException("underlying native object already deleted");
    return swigCPtr;
  }
  
  /**
   * Create a new IPixelFormat object that is actually referring to the
   * exact same underlying native object.
   *
   * @return the new Java object.
   */
  @Override
  public IPixelFormat copyReference() {
    if (swigCPtr == 0)
      return null;
    else
      return new IPixelFormat(swigCPtr, swigCMemOwn, getJavaRefCount());
  }

  /**
   * Compares two values, returning true if the underlying objects in native code are the same object.
   *
   * That means you can have two different Java objects, but when you do a comparison, you'll find out
   * they are the EXACT same object.
   *
   * @return True if the underlying native object is the same.  False otherwise.
   */
  public boolean equals(Object obj) {
    boolean equal = false;
    if (obj instanceof IPixelFormat)
      equal = (((IPixelFormat)obj).swigCPtr == this.swigCPtr);
    return equal;
  }
  
  /**
   * Get a hashable value for this object.
   *
   * @return the hashable value.
   */
  public int hashCode() {
     return (int)swigCPtr;
  }
  
  // <<<<<<<<<<<<<<<<<<<<<<<<<<<
  // JNIHelper.swg: End generated code
  
/**
 * Returns the byte for the coordinates at x and y for the color component 
 * c.  
 * @param	frame The frame to get the byte from  
 * @param	x X coordinate in pixels, where 0 is the left hand edge of 
 *		 the image.  
 * @param	y Y coordinate in pixels, where 0 is the top edge of the image. 
 *		  
 * @param	c YUVColor component  
 * @throws	std::exception frame is null, the coordinates are invalid, 
 *		 or if the pixel format is not YUV420P  
 * @return	the pixel byte for that x, y, c combination  
 */
  public static short getYUV420PPixel(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c) {
    return XugglerJNI.IPixelFormat_getYUV420PPixel(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue());
  }

/**
 * Sets the value of the color component c at the coordinates x and 
 * y in the given frame.  
 * @param	frame The frame to set the byte in  
 * @param	x X coordinate in pixels, where 0 is the left hand edge of 
 *		 the image.  
 * @param	y Y coordinate in pixels, where 0 is the top edge of the image. 
 *		  
 * @param	c YUVColor component to set  
 * @param	value The new value of that pixel color component  
 * @throws	std::exception frame is null, the coordinates are invalid, 
 *		 or if the pixel format is not YUV420P  
 */
  public static void setYUV420PPixel(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c, short value) {
    XugglerJNI.IPixelFormat_setYUV420PPixel(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue(), value);
  }

/**
 * For a given x and y in a frame, and a given color components, this 
 * method  
 * tells you how far into the actual data you'd have to go to find the 
 * byte that  
 * represents that color/coordinate combination.  
 * @param	frame The frame to get the byte from  
 * @param	x X coordinate in pixels, where 0 is the left hand edge of 
 *		 the image.  
 * @param	y Y coordinate in pixels, where 0 is the top edge of the image. 
 *		  
 * @param	c YUVColor component  
 * @throws	std::exception frame is null, the coordinates are invalid, 
 *		 or if the pixel format is not YUV420P  
 * @return	the offset in bytes, starting from the start of the frame 
 *		 data, where  
 * the data for this pixel resides.  
 */
  public static int getYUV420PPixelOffset(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c) {
    return XugglerJNI.IPixelFormat_getYUV420PPixelOffset(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue());
  }

  public enum Type {
  /**
   * Pixel format. Notes:
   * RGB32 is handled in an endian-specific manner. A RGBA
   * color is put together as:
   * (A << 24) | (R << 16) | (G << 8) | B
   * This is stored as BGRA on little endian CPU architectures and ARGB 
   * on
   * big endian CPUs.
   * When the pixel format is palettized RGB (PAL8), the palettized
   * image data is stored in AVFrame.data[0]. The palette is transported 
   * in
   * AVFrame.data[1] and, is 1024 bytes long (256 4-byte entries) and 
   * is
   * formatted the same as in RGB32 described above (i.e., it is
   * also endian-specific). Note also that the individual RGB palette 
   *
   * components stored in AVFrame.data[1] should be in the range 0..255. 
   *
   * This is important as many custom PAL8 video codecs that were designed 
   *
   * to run on the IBM VGA graphics adapter use 6-bit palette components. 
   *
   */
    NONE(XugglerJNI.IPixelFormat_NONE_get()),
  /**
   * planar YUV 4:2:0, 12bpp, (1 Cr & Cb sample per 2x2 Y samples)
   */
    YUV420P,
  /**
   * packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr
   */
    YUYV422,
  /**
   * packed RGB 8:8:8, 24bpp, RGBRGB...
   */
    RGB24,
  /**
   * packed RGB 8:8:8, 24bpp, BGRBGR...
   */
    BGR24,
  /**
   * planar YUV 4:2:2, 16bpp, (1 Cr & Cb sample per 2x1 Y samples)
   */
    YUV422P,
  /**
   * planar YUV 4:4:4, 24bpp, (1 Cr & Cb sample per 1x1 Y samples)
   */
    YUV444P,
  /**
   * planar YUV 4:1:0, 9bpp, (1 Cr & Cb sample per 4x4 Y samples)
   */
    YUV410P,
  /**
   * planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples)
   */
    YUV411P,
  /**
   * Y , 8bpp
   */
    GRAY8,
  /**
   * Y , 1bpp, 0 is white, 1 is black, in each byte pixels are ordered 
   * from the msb to the lsb
   */
    MONOWHITE,
  /**
   * Y , 1bpp, 0 is black, 1 is white, in each byte pixels are ordered 
   * from the msb to the lsb
   */
    MONOBLACK,
  /**
   * 8 bit with RGB32 palette
   */
    PAL8,
  /**
   * planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated in favor of 
   * YUV420P and setting color_range
   */
    YUVJ420P,
  /**
   * planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated in favor of 
   * YUV422P and setting color_range
   */
    YUVJ422P,
  /**
   * planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated in favor of 
   * YUV444P and setting color_range
   */
    YUVJ444P,
  /**
   * XVideo Motion Acceleration via common packet passing
   */
    XVMC_MPEG2_MC,
    XVMC_MPEG2_IDCT,
  /**
   * packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1
   */
    UYVY422,
  /**
   * packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3
   */
    UYYVYY411,
  /**
   * packed RGB 3:3:2, 8bpp, (msb)2B 3G 3R(lsb)
   */
    BGR8,
  /**
   * packed RGB 1:2:1 bitstream, 4bpp, (msb)1B 2G 1R(lsb), a byte contains 
   * two pixels, the first pixel in the byte is the one composed by the 
   * 4 msb bits
   */
    BGR4,
  /**
   * packed RGB 1:2:1, 8bpp, (msb)1B 2G 1R(lsb)
   */
    BGR4_BYTE,
  /**
   * packed RGB 3:3:2, 8bpp, (msb)2R 3G 3B(lsb)
   */
    RGB8,
  /**
   * packed RGB 1:2:1 bitstream, 4bpp, (msb)1R 2G 1B(lsb), a byte contains 
   * two pixels, the first pixel in the byte is the one composed by the 
   * 4 msb bits
   */
    RGB4,
  /**
   * packed RGB 1:2:1, 8bpp, (msb)1R 2G 1B(lsb)
   */
    RGB4_BYTE,
  /**
   * planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, 
   * which are interleaved (first byte U and the following byte V)
   */
    NV12,
  /**
   * as above, but U and V bytes are swapped
   */
    NV21,
  /**
   * packed ARGB 8:8:8:8, 32bpp, ARGBARGB...
   */
    ARGB,
  /**
   * packed RGBA 8:8:8:8, 32bpp, RGBARGBA...
   */
    RGBA,
  /**
   * packed ABGR 8:8:8:8, 32bpp, ABGRABGR...
   */
    ABGR,
  /**
   * packed BGRA 8:8:8:8, 32bpp, BGRABGRA...
   */
    BGRA,
  /**
   * Y , 16bpp, big-endian
   */
    GRAY16BE,
  /**
   * Y , 16bpp, little-endian
   */
    GRAY16LE,
  /**
   * planar YUV 4:4:0 (1 Cr & Cb sample per 1x2 Y samples)
   */
    YUV440P,
  /**
   * planar YUV 4:4:0 full scale (JPEG), deprecated in favor of YUV440P 
   * and setting color_range
   */
    YUVJ440P,
  /**
   * planar YUV 4:2:0, 20bpp, (1 Cr & Cb sample per 2x2 Y & A samples) 
   *
   */
    YUVA420P,
  /**
   * H.264 HW decoding with VDPAU, data[0] contains a vdpau_render_state 
   * struct which contains the bitstream of the slices as well as various 
   * fields extracted from headers
   */
    VDPAU_H264,
  /**
   * MPEG-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state 
   * struct which contains the bitstream of the slices as well as various 
   * fields extracted from headers
   */
    VDPAU_MPEG1,
  /**
   * MPEG-2 HW decoding with VDPAU, data[0] contains a vdpau_render_state 
   * struct which contains the bitstream of the slices as well as various 
   * fields extracted from headers
   */
    VDPAU_MPEG2,
  /**
   * WMV3 HW decoding with VDPAU, data[0] contains a vdpau_render_state 
   * struct which contains the bitstream of the slices as well as various 
   * fields extracted from headers
   */
    VDPAU_WMV3,
  /**
   * VC-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state 
   * struct which contains the bitstream of the slices as well as various 
   * fields extracted from headers
   */
    VDPAU_VC1,
  /**
   * packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each 
   * R/G/B component is stored as big-endian
   */
    RGB48BE,
  /**
   * packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each 
   * R/G/B component is stored as little-endian
   */
    RGB48LE,
  /**
   * packed RGB 5:6:5, 16bpp, (msb) 5R 6G 5B(lsb), big-endian
   */
    RGB565BE,
  /**
   * packed RGB 5:6:5, 16bpp, (msb) 5R 6G 5B(lsb), little-endian
   */
    RGB565LE,
  /**
   * packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), big-endian, most 
   * significant bit to 0
   */
    RGB555BE,
  /**
   * packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), little-endian, most 
   * significant bit to 0
   */
    RGB555LE,
  /**
   * packed BGR 5:6:5, 16bpp, (msb) 5B 6G 5R(lsb), big-endian
   */
    BGR565BE,
  /**
   * packed BGR 5:6:5, 16bpp, (msb) 5B 6G 5R(lsb), little-endian
   */
    BGR565LE,
  /**
   * packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), big-endian, most 
   * significant bit to 1
   */
    BGR555BE,
  /**
   * packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), little-endian, most 
   * significant bit to 1
   */
    BGR555LE,
  /**
   * HW acceleration through VA API at motion compensation entry-point, 
   * Picture.data[3] contains a vaapi_render_state struct which contains 
   * macroblocks as well as various fields extracted from headers
   */
    VAAPI_MOCO,
  /**
   * HW acceleration through VA API at IDCT entry-point, Picture.data[3] 
   * contains a vaapi_render_state struct which contains fields extracted 
   * from headers
   */
    VAAPI_IDCT,
  /**
   * HW decoding through VA API, Picture.data[3] contains a vaapi_render_state 
   * struct which contains the bitstream of the slices as well as various 
   * fields extracted from headers
   */
    VAAPI_VLD,
  /**
   * planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian 
   *
   */
    YUV420P16LE,
  /**
   * planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian 
   *
   */
    YUV420P16BE,
  /**
   * planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian 
   *
   */
    YUV422P16LE,
  /**
   * planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian 
   *
   */
    YUV422P16BE,
  /**
   * planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian 
   *
   */
    YUV444P16LE,
  /**
   * planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian 
   *
   */
    YUV444P16BE,
  /**
   * MPEG4 HW decoding with VDPAU, data[0] contains a vdpau_render_state 
   * struct which contains the bitstream of the slices as well as various 
   * fields extracted from headers
   */
    VDPAU_MPEG4,
  /**
   * HW decoding through DXVA2, Picture.data[3] contains a LPDIRECT3DSURFACE9 
   * pointer
   */
    DXVA2_VLD,
  /**
   * packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), little-endian, most 
   * significant bits to 0
   */
    RGB444LE,
  /**
   * packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), big-endian, most 
   * significant bits to 0
   */
    RGB444BE,
  /**
   * packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), little-endian, most 
   * significant bits to 1
   */
    BGR444LE,
  /**
   * packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), big-endian, most 
   * significant bits to 1
   */
    BGR444BE,
  /**
   * 8bit gray, 8bit alpha
   */
    GRAY8A,
  /**
   * packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each 
   * R/G/B component is stored as big-endian
   */
    BGR48BE,
  /**
   * packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each 
   * R/G/B component is stored as little-endian
   */
    BGR48LE,
  /**
   * planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), 
   * big-endian
   */
    YUV420P9BE,
  /**
   * planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), 
   * little-endian
   */
    YUV420P9LE,
  /**
   * planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian 
   *
   */
    YUV420P10BE,
  /**
   * planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian 
   *
   */
    YUV420P10LE,
  /**
   * planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian 
   *
   */
    YUV422P10BE,
  /**
   * planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian 
   *
   */
    YUV422P10LE,
  /**
   * planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian 
   *
   */
    YUV444P9BE,
  /**
   * planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian 
   *
   */
    YUV444P9LE,
  /**
   * planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian 
   *
   */
    YUV444P10BE,
  /**
   * planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian 
   *
   */
    YUV444P10LE,
  /**
   * planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian 
   *
   */
    YUV422P9BE,
  /**
   * planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian 
   *
   */
    YUV422P9LE,
  /**
   * hardware decoding through VDA
   */
    VDA_VLD,
  /**
   * planar GBR 4:4:4 24bpp
   */
    GBRP,
  /**
   * planar GBR 4:4:4 27bpp, big endian
   */
    GBRP9BE,
  /**
   * planar GBR 4:4:4 27bpp, little endian
   */
    GBRP9LE,
  /**
   * planar GBR 4:4:4 30bpp, big endian
   */
    GBRP10BE,
  /**
   * planar GBR 4:4:4 30bpp, little endian
   */
    GBRP10LE,
  /**
   * planar GBR 4:4:4 48bpp, big endian
   */
    GBRP16BE,
  /**
   * planar GBR 4:4:4 48bpp, little endian
   */
    GBRP16LE,
  /**
   * packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value 
   * for each R/G/B/A component is stored as big-endian
   */
    RGBA64BE(XugglerJNI.IPixelFormat_RGBA64BE_get()),
  /**
   * packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value 
   * for each R/G/B/A component is stored as little-endian
   */
    RGBA64LE,
  /**
   * packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value 
   * for each R/G/B/A component is stored as big-endian
   */
    BGRA64BE,
  /**
   * packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value 
   * for each R/G/B/A component is stored as little-endian
   */
    BGRA64LE,
  /**
   * packed RGB 8:8:8, 32bpp, 0RGB0RGB...
   */
    ZRGB(XugglerJNI.IPixelFormat_ZRGB_get()),
  /**
   * packed RGB 8:8:8, 32bpp, RGB0RGB0...
   */
    RGB0,
  /**
   * packed BGR 8:8:8, 32bpp, 0BGR0BGR...
   */
    ZBGR,
  /**
   * packed BGR 8:8:8, 32bpp, BGR0BGR0...
   */
    BGR0,
  /**
   * planar YUV 4:4:4 32bpp, (1 Cr & Cb sample per 1x1 Y & A samples) 
   *
   */
    YUVA444P,
  /**
   * number of pixel formats, DO NOT USE THIS if you want to link with 
   * shared libav* because the number of formats might differ between 
   * versions
   */
    NB;

    public final int swigValue() {
      return swigValue;
    }

    public static Type swigToEnum(int swigValue) {
      Type[] swigValues = Type.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (Type swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + Type.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private Type() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private Type(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private Type(Type swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

  public enum YUVColorComponent {
    YUV_Y(XugglerJNI.IPixelFormat_YUV_Y_get()),
    YUV_U(XugglerJNI.IPixelFormat_YUV_U_get()),
    YUV_V(XugglerJNI.IPixelFormat_YUV_V_get());

    public final int swigValue() {
      return swigValue;
    }

    public static YUVColorComponent swigToEnum(int swigValue) {
      YUVColorComponent[] swigValues = YUVColorComponent.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (YUVColorComponent swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + YUVColorComponent.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private YUVColorComponent() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private YUVColorComponent(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private YUVColorComponent(YUVColorComponent swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

}
